{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPYBu7vQofyE7D+7RkchD4I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjordana/twitter_sentiment_analysis/blob/master/roBERTa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA-asSSyTMIs",
        "colab_type": "text"
      },
      "source": [
        "## Kaggle's API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ngHlaFWL8po",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir .kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSRkb3OyQfVM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "token = {\"username\":\"jjordana16\",\"key\":\"6e806145f7c3fdd4c09e7299f3a70d73\"}\n",
        "with open('/content/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHaSVGULQ9cE",
        "colab_type": "code",
        "outputId": "67a1c0a3-333d-4a05-8d3e-9d1e70bd5a14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v/content"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "- path is now set to: /content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdrcnSQZQv1w",
        "colab_type": "code",
        "outputId": "d90e9016-a26f-4cda-e795-ce5e1b82bb27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!kaggle competitions download -c tweet-sentiment-extraction"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading train.csv.zip to /content/competitions/tweet-sentiment-extraction\n",
            "\r  0% 0.00/1.23M [00:00<?, ?B/s]\n",
            "100% 1.23M/1.23M [00:00<00:00, 68.5MB/s]\n",
            "Downloading sample_submission.csv to /content/competitions/tweet-sentiment-extraction\n",
            "  0% 0.00/41.4k [00:00<?, ?B/s]\n",
            "100% 41.4k/41.4k [00:00<00:00, 35.8MB/s]\n",
            "Downloading test.csv to /content/competitions/tweet-sentiment-extraction\n",
            "  0% 0.00/307k [00:00<?, ?B/s]\n",
            "100% 307k/307k [00:00<00:00, 95.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D4fxDb_TPDX",
        "colab_type": "text"
      },
      "source": [
        "## Importing Libraries & data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tATfE7r5i7ij",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d17490e4-ec76-4531-fd1f-86c514efdbbd"
      },
      "source": [
        "import pandas as pd, numpy as np\n",
        "import tensorflow as tf\n",
        "print('TF version',tf.__version__)\n",
        "import tensorflow.keras.backend as K\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF version 2.2.0-rc4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLwZ4tVqjBC9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf8UhRWhjLa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import *\n",
        "import tokenizers\n",
        "from tokenizers import ByteLevelBPETokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YwjmcA1MBHCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('/content/competitions/tweet-sentiment-extraction/train.csv.zip').fillna('')\n",
        "train = train.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN3Rv4Ux-7r5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = ByteLevelBPETokenizer(\n",
        "    add_prefix_space=True, \n",
        "    lowercase=True,\n",
        "    vocab_file='vocab-roberta-vocab.json', \n",
        "    merges_file='vocab-roberta-merges.txt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOG9IBrhBRZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer.train([\"/content/train.csv\"], vocab_size=20000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDbaWnLkCm_g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2390adb2-222a-4bf3-e98e-53b37c905a77"
      },
      "source": [
        "tokenizer.save(directory=\"/content/\", name='vocab-roberta')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/vocab-roberta-vocab.json', '/content/vocab-roberta-merges.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47-bDYGwF6NB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "60fbf878-d33b-4063-ee3f-dab43b8fe7f5"
      },
      "source": [
        "MAX_LEN = 96\n",
        "EPOCHS = 3\n",
        "BATCH_SIZE = 32\n",
        "PAD_ID = 1\n",
        "SEED = 777\n",
        "LABEL_SMOOTHING = 0.1\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "sentiment_id = {'positive': 1313, 'negative': 2430, 'neutral': 7974}\n",
        "train.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>textID</th>\n",
              "      <th>text</th>\n",
              "      <th>selected_text</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cb774db0d1</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>I`d have responded, if I were going</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>549e992a42</td>\n",
              "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
              "      <td>Sooo SAD</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>088c60f138</td>\n",
              "      <td>my boss is bullying me...</td>\n",
              "      <td>bullying me</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9642c003ef</td>\n",
              "      <td>what interview! leave me alone</td>\n",
              "      <td>leave me alone</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>358bd9e861</td>\n",
              "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
              "      <td>Sons of ****,</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       textID  ... sentiment\n",
              "0  cb774db0d1  ...   neutral\n",
              "1  549e992a42  ...  negative\n",
              "2  088c60f138  ...  negative\n",
              "3  9642c003ef  ...  negative\n",
              "4  358bd9e861  ...  negative\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwY75FdQGwrw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rowsFile = train.shape[0]\n",
        "input_ids = np.ones((rowsFile,MAX_LEN),dtype='int32')\n",
        "attention_mask = np.zeros((rowsFile,MAX_LEN),dtype='int32')\n",
        "token_type_ids = np.zeros((rowsFile,MAX_LEN),dtype='int32')\n",
        "start_tokens = np.zeros((rowsFile,MAX_LEN),dtype='int32')\n",
        "end_tokens = np.zeros((rowsFile,MAX_LEN),dtype='int32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isaLt2NGQqpC",
        "colab_type": "text"
      },
      "source": [
        "We have already our tokenized our data.\n",
        "\n",
        "1. Firstly, we find the index in which our `selected_text` starts in our `text` <br>(i.e. if out tweet is _\"I love singning under the rain\"_ and our selected_text _love singing_, we will find the index where it starts.<br>\n",
        "It will be `3`).<br>\n",
        "2. In an empty vector, `chars`, full of 0s, we fulfill it with ones where the text and selected_text `coincide`. <br>\n",
        "3. We **encode** our tweet using the __tokenicer__. <br>\n",
        "4. We get the whole length for each tweet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuTZJm02IMBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for val in range(rowsFile):\n",
        "  # FIND OVERLAP\n",
        "  text1 = \" \" + \" \".join(train.loc[val,'text'].split())\n",
        "  text2 = \" \".join(train.loc[val,'selected_text'].split())\n",
        "\n",
        "  idx = text1.find(text2) # We find index where our selected_word starts\n",
        "  chars = np.zeros((len(text1))) # We create a vector of 0s with the length of text\n",
        "  chars[idx:idx+len(text2)] = 1 # Fullfill the vector with 1 when it coincides\n",
        "  if text1[idx-1]==' ': chars[idx-1] = 1 \n",
        "  enc = tokenizer.encode(text1) \n",
        "\n",
        "  # ID_OFFSETS\n",
        "  offsets = []\n",
        "  idx=0\n",
        "  for t in enc.ids:\n",
        "    w = tokenizer.decode([t])\n",
        "    offsets.append((idx,idx+len(w)))\n",
        "    idx += len(w)\n",
        "\n",
        "  # START END TOKENS\n",
        "  toks = []\n",
        "  for i,(a,b) in enumerate(offsets):  \n",
        "    sm = np.sum(chars[a:b])\n",
        "    if sm>0: toks.append(i) \n",
        "        \n",
        "  s_tok = sentiment_id[train.loc[val,'sentiment']]\n",
        "  input_ids[val,:len(enc.ids) + 5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n",
        "  attention_mask[val,:len(enc.ids)+5] = 1\n",
        "  if len(toks)>0:\n",
        "    start_tokens[val,toks[0]+1] = 1\n",
        "    end_tokens[val,toks[-1]+1] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnuXHLWJV1nC",
        "colab_type": "text"
      },
      "source": [
        "TEST DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FyG58I6N4CS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = pd.read_csv('/content/competitions/tweet-sentiment-extraction/test.csv').fillna('')\n",
        "rowsFile = test.shape[0]\n",
        "input_ids_t = np.ones((rowsFile,MAX_LEN),dtype='int32')\n",
        "attention_mask_t = np.zeros((rowsFile,MAX_LEN),dtype='int32')\n",
        "token_type_ids_t = np.zeros((rowsFile,MAX_LEN),dtype='int32')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgmOf1QpWTjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for k in range(rowsFile):   \n",
        "  # INPUT_IDS\n",
        "  text1 = \" \"+\" \".join(test.loc[k,'text'].split())\n",
        "  enc = tokenizer.encode(text1)                \n",
        "  s_tok = sentiment_id[test.loc[k,'sentiment']]\n",
        "  input_ids_t[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n",
        "  attention_mask_t[k,:len(enc.ids)+5] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmPGzpyaZNdt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "r = requests.get('https://s3.amazonaws.com/models.huggingface.co/bert/distilroberta-base-config.json')\n",
        "data = r.json()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fg9j7HF1a36J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import requests\n",
        "\n",
        "solditems = requests.get('https://s3.amazonaws.com/models.huggingface.co/bert/distilroberta-base-config.json') # (your url)\n",
        "data = solditems.json()\n",
        "with open('data.json', 'w') as f:\n",
        "    json.dump(data, f)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}